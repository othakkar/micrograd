{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be79a882-7adf-44c5-a7e4-590b12c9d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91872f93-1b52-4805-a554-4d5808f494d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install graphviz\n",
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "    nodes, edges = set(), set()\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "def draw_dot(root, format='svg', rankdir='LR'):\n",
    "    \"\"\"\n",
    "    format: png | svg | ...\n",
    "    rankdir: TB (top to bottom graph) | LR (left to right)\n",
    "    \"\"\"\n",
    "    assert rankdir in ['LR', 'TB']\n",
    "    nodes, edges = trace(root)\n",
    "    dot = Digraph(format=format, graph_attr={'rankdir': rankdir}) #, node_attr={'rankdir': 'TB'})\n",
    "    \n",
    "    for n in nodes:\n",
    "        dot.node(name=str(id(n)), label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')\n",
    "        if n._op:\n",
    "            dot.node(name=str(id(n)) + n._op, label=n._op)\n",
    "            dot.edge(str(id(n)) + n._op, str(id(n)))\n",
    "    \n",
    "    for n1, n2 in edges:\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "    \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5feaaf-efa4-4da6-b9e6-ea52d54f54ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    \"\"\" stores a single scalar value and its gradient \"\"\"\n",
    "\n",
    "    def __init__(self, data, _children=(), _op='', label=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        # internal variables\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self._backward = lambda: None\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "\n",
    "    def __add__(self, other): # self + other\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        \n",
    "        self._backward = _backward\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other): # self * other\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        \n",
    "        self._backward = _backward\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"only supporting int & float powers\"\n",
    "        out = Value(math.pow(self.data, other), (self, ), 'pow')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (other * (self.data ** (other - 1))) * out.grad\n",
    "        \n",
    "        self._backward = _backward\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def exp(self):\n",
    "        out = Value(math.exp(self.data), (self, ), 'exp')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.data * out.grad\n",
    "        \n",
    "        self._backward = _backward\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def tanh(self):\n",
    "        e = math.exp(2 * self.data)\n",
    "        t = (e - 1) / (e + 1)\n",
    "        out = Value(t, (self, ), 'tanh')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1 - t**2) * out.grad\n",
    "        \n",
    "        self._backward = _backward\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def relu(self):\n",
    "        out = Value(max(self.data, 0.0), (self, ), 'relu')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (out.data > 0) * out.grad\n",
    "        \n",
    "        self._backward = _backward\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "\n",
    "    def __radd__(self, other): # other + self\n",
    "        return self + other\n",
    "\n",
    "    def __rmul__(self, other): # other * self\n",
    "        return self * other\n",
    "\n",
    "    def __neg__(self): # -self\n",
    "        return -1.0 * self\n",
    "\n",
    "    def __rsub__(self, other): # other - self\n",
    "        return other + (-self)\n",
    "\n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)\n",
    "\n",
    "    def __rtruediv__(self, other): # other / self\n",
    "        return other * (self ** -1)\n",
    "\n",
    "    def __truediv__(self, other): # self / other\n",
    "        return self * (other ** -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2cc332-3aae-4cef-814e-2b46b98337f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: x1, x2\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "# weights: w1, w2\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "# x1*w1 + x2*w2 + b\n",
    "x1w1 = x1 * w1; x1w1.label = 'x1w1'\n",
    "x2w2 = x2 * w2; x2w2.label = 'x2w2'\n",
    "b = Value(6.8813735870195, label='b')\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1x2w2'\n",
    "n = x1w1x2w2 + b; n.label = 'n'\n",
    "o = n.relu(); o.label = 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e2d11-99a7-4f37-9f14-1db2d47b6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c6703-52df-4ed0-9253-ee38086770dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310c745a-1d71-4e22-a156-891f1d3b132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0.0\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Neuron(Module):\n",
    "\n",
    "    def __init__(self, n_ins):\n",
    "        self.w = [Value(random.uniform(-1, 1)) for _ in range(n_ins)]\n",
    "        self.b = Value(random.uniform(-1, 1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        act = sum([xi * wi for xi, wi in zip(x, self.w)], self.b)\n",
    "        out = act.tanh()\n",
    "        return act\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "\n",
    "class Layer(Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.neurons = [Neuron(n_in) for _ in range(n_out)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for n in self.neurons for p in n.parameters()]\n",
    "\n",
    "class MLP(Module):\n",
    "\n",
    "    def __init__(self, n_in, n_outs):\n",
    "        sz = [n_in] + n_outs\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(n_outs))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c419ea-e630-4ce7-a1fd-b907c0d0e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0]\n",
    "n = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4d02d2-ceeb-492e-bd9e-5b1698fb9726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr: 0, loss: 23.008284180874877\n",
      "itr: 1, loss: 15.44274587979545\n",
      "itr: 2, loss: 7.9482040858849805\n",
      "itr: 3, loss: 29.55912324131421\n",
      "itr: 4, loss: 5.56638184090358\n",
      "itr: 5, loss: 2.862866075511343\n",
      "itr: 6, loss: 3.207801183152697\n",
      "itr: 7, loss: 2.635607554937067\n",
      "itr: 8, loss: 1.7533389047497792\n",
      "itr: 9, loss: 1.3171221025928388\n",
      "itr: 10, loss: 0.2635415588493433\n",
      "itr: 11, loss: 0.36197596731430887\n",
      "itr: 12, loss: 0.5864442138736787\n",
      "itr: 13, loss: 1.3733459173896536\n",
      "itr: 14, loss: 1.0366880379996768\n",
      "itr: 15, loss: 0.41410658858565985\n",
      "itr: 16, loss: 0.4036836472634331\n",
      "itr: 17, loss: 0.09617201764959686\n",
      "itr: 18, loss: 0.17949993673007136\n",
      "itr: 19, loss: 0.12480593795585805\n",
      "itr: 20, loss: 0.0652314299368495\n",
      "itr: 21, loss: 0.07128988199611971\n",
      "itr: 22, loss: 0.04282409378936507\n",
      "itr: 23, loss: 0.06022795505597622\n",
      "itr: 24, loss: 0.03895869961930819\n",
      "itr: 25, loss: 0.01504205814630587\n",
      "itr: 26, loss: 0.008037442882249364\n",
      "itr: 27, loss: 0.010215537242594002\n",
      "itr: 28, loss: 0.020701506124887834\n",
      "itr: 29, loss: 0.018972412575043462\n",
      "itr: 30, loss: 0.025271053342668524\n",
      "itr: 31, loss: 0.015466296716117812\n",
      "itr: 32, loss: 0.013290339085800363\n",
      "itr: 33, loss: 0.002389338063998327\n",
      "itr: 34, loss: 0.0005618373048097943\n",
      "itr: 35, loss: 0.0005875375924190798\n",
      "itr: 36, loss: 0.0009145992196663848\n",
      "itr: 37, loss: 0.0006020185326798656\n",
      "itr: 38, loss: 0.0007076376234634171\n",
      "itr: 39, loss: 0.0009561595111375848\n",
      "itr: 40, loss: 0.0012769373661184085\n",
      "itr: 41, loss: 0.001826476966664629\n",
      "itr: 42, loss: 0.0007459460805716832\n",
      "itr: 43, loss: 0.000809140972222922\n",
      "itr: 44, loss: 0.000691104946135094\n",
      "itr: 45, loss: 0.000691104946135094\n",
      "itr: 46, loss: 0.0005185105005708266\n",
      "itr: 47, loss: 0.0004943433171339268\n",
      "itr: 48, loss: 0.0007472631961984382\n",
      "itr: 49, loss: 0.0003560530929132828\n",
      "itr: 50, loss: 0.0002223723005325387\n",
      "itr: 51, loss: 0.00032811125537934795\n",
      "itr: 52, loss: 0.0003420876462844112\n",
      "itr: 53, loss: 0.00030194552796478997\n",
      "itr: 54, loss: 0.00011761241035371864\n",
      "itr: 55, loss: 0.000134034154832357\n",
      "itr: 56, loss: 0.00010261233300252425\n",
      "itr: 57, loss: 1.3992326719343719e-05\n",
      "itr: 58, loss: 2.685256200858725e-05\n",
      "itr: 59, loss: 3.24426795753352e-05\n",
      "itr: 60, loss: 2.628929084856104e-05\n",
      "itr: 61, loss: 2.6079265608980118e-05\n",
      "itr: 62, loss: 2.5863792795197776e-05\n",
      "itr: 63, loss: 5.194488681175613e-05\n",
      "itr: 64, loss: 3.837369178773001e-05\n",
      "itr: 65, loss: 3.310664883213485e-05\n",
      "itr: 66, loss: 3.099362806140624e-05\n",
      "itr: 67, loss: 6.437127951553421e-05\n",
      "itr: 68, loss: 3.093505085158999e-05\n",
      "itr: 69, loss: 2.407201548723761e-05\n",
      "itr: 70, loss: 3.1015957866719394e-05\n",
      "itr: 71, loss: 3.851657471626235e-05\n",
      "itr: 72, loss: 7.2851509651070565e-06\n",
      "itr: 73, loss: 1.2774170326615483e-05\n",
      "itr: 74, loss: 1.4511520947641006e-05\n",
      "itr: 75, loss: 1.4516604542117061e-05\n",
      "itr: 76, loss: 1.719247312046154e-05\n",
      "itr: 77, loss: 5.257414455315478e-06\n",
      "itr: 78, loss: 5.043616363892905e-06\n",
      "itr: 79, loss: 3.795770008556059e-06\n",
      "itr: 80, loss: 3.1804599708566677e-06\n",
      "itr: 81, loss: 3.249334166173322e-06\n",
      "itr: 82, loss: 2.962563272621915e-06\n",
      "itr: 83, loss: 6.361492000804825e-06\n",
      "itr: 84, loss: 2.112348452681086e-06\n",
      "itr: 85, loss: 2.782021822455735e-06\n",
      "itr: 86, loss: 1.4843613932423083e-06\n",
      "itr: 87, loss: 1.3747429472403939e-06\n",
      "itr: 88, loss: 2.9523025111557715e-06\n",
      "itr: 89, loss: 1.4449220598392436e-06\n",
      "itr: 90, loss: 1.4824096236891001e-06\n",
      "itr: 91, loss: 6.581944264774984e-07\n",
      "itr: 92, loss: 4.794368879777477e-07\n",
      "itr: 93, loss: 2.4944463116827395e-07\n",
      "itr: 94, loss: 2.460966300497517e-07\n",
      "itr: 95, loss: 2.291071151329516e-07\n",
      "itr: 96, loss: 4.407981070591756e-07\n",
      "itr: 97, loss: 2.0239568260948348e-07\n",
      "itr: 98, loss: 6.77702944754122e-08\n",
      "itr: 99, loss: 6.244684000161706e-08\n"
     ]
    }
   ],
   "source": [
    "for itr in range(100):\n",
    "    # forward pass\n",
    "    ypreds = [n(x) for x in xs]\n",
    "\n",
    "    # loss\n",
    "    loss = sum((ypred - ytgt)**2 for ypred, ytgt in zip(ypreds, ys))\n",
    "    print(f\"itr: {itr}, loss: {loss.data}\")\n",
    "\n",
    "    # zero grad\n",
    "    n.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # parameter update\n",
    "    for p in n.parameters():\n",
    "        p.data += (-0.1) * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118e41f9-76bf-451c-9761-be12b1d78961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.999840993523653),\n",
       " Value(data=-0.9999614495332027),\n",
       " Value(data=-1.000164477187989),\n",
       " Value(data=1.0000928703215364)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ebdd19a-ef93-4347-a78e-fe3d6e90da4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, -1.0, -1.0, 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e702ea-8d74-4b93-8330-31718a4b5899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
